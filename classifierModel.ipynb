{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f2f1dc-914d-4fcd-8e32-12454feb987b",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224601b6-544c-45a1-b54f-dc07ea11f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdcddfe5-e045-4a91-aa25-702e4ca106e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88348fa5-7d3a-407f-a6af-822ba452a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8d0141-7978-4700-ba0a-66991d9d79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras as keras\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib as plt\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa3642c-f52d-4be2-978b-c1d85cd36cfd",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e37c8b-f54e-4f10-add2-ac63e2426873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardboard',\n",
       " 'glass',\n",
       " 'metal',\n",
       " 'nothing',\n",
       " 'organic',\n",
       " 'paper',\n",
       " 'plastic',\n",
       " 'trash']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('dataset-resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0bff86-6be6-44cc-8835-964ff5313437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#reading an image\n",
    "img = cv2.imread(os.path.join('dataset-resized','nothing','0.jpg'))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f8c283-3ea7-4e13-a2a3-546ad2d3d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothing = glob.glob(os.path.join('dataset-resized','nothing','*.jpg'))\n",
    "cardboard = glob.glob(os.path.join('dataset-resized','cardboard','*.jpg'))\n",
    "glass = glob.glob(os.path.join('dataset-resized','glass','*.jpg'))\n",
    "metal = glob.glob(os.path.join('dataset-resized','metal','*.jpg'))\n",
    "organic = glob.glob(os.path.join('dataset-resized','organic','*.jpg'))\n",
    "paper = glob.glob(os.path.join('dataset-resized','paper','*.jpg'))\n",
    "plastic = glob.glob(os.path.join('dataset-resized','plastic','*.jpg'))\n",
    "trash = glob.glob(os.path.join('dataset-resized','trash','*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3570730c-9d7d-4326-bff0-232b4da56e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e564503-e3e7-4a55-9a82-0a373f5206d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:01<00:00, 468.83it/s]\n",
      "100%|██████████| 403/403 [00:01<00:00, 297.47it/s]\n",
      "100%|██████████| 501/501 [00:01<00:00, 313.87it/s]\n",
      "100%|██████████| 410/410 [00:01<00:00, 308.92it/s]\n",
      "100%|██████████| 1401/1401 [00:03<00:00, 418.34it/s]\n",
      "100%|██████████| 594/594 [00:02<00:00, 241.67it/s]\n",
      "100%|██████████| 482/482 [00:01<00:00, 335.35it/s]\n",
      "100%|██████████| 137/137 [00:00<00:00, 334.15it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for i in tqdm(nothing):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "    \n",
    "for i in tqdm(cardboard):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "\n",
    "for i in tqdm(glass):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(2)\n",
    "    \n",
    "for i in tqdm(metal):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(3)\n",
    "\n",
    "for i in tqdm(organic):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(4)\n",
    "    \n",
    "for i in tqdm(paper):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(5)\n",
    "    \n",
    "for i in tqdm(plastic):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(6)\n",
    "    \n",
    "for i in tqdm(trash):   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    target_size= (384,512))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(7)\n",
    "    \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad45c344-cfa1-402a-9fb5-003fe27537bf",
   "metadata": {},
   "source": [
    "## Creating an encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f82ebefd-7c4d-45d0-b861-2a7b34b8f7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 382, 510, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 191, 255, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 189, 253, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 94, 126, 64)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 92, 124, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 46, 62, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 46, 62, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 365056)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               93454592  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,547,840\n",
      "Trainable params: 93,547,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_encoder():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),input_shape=(384,512,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "        \n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu')])\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9026ab-06ff-4a95-a2a3-4b4c218d0c7e",
   "metadata": {},
   "source": [
    "## Creating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad287d9-dc17-496a-86c2-ac6a794ebab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=(384,512,3))\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(0.1)(features)\n",
    "    features = layers.Dense(512, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(0.1)(features)\n",
    "    outputs = layers.Dense(8, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(0.001),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42f8a2-3fad-4a2c-9e87-aafd04fdec9c",
   "metadata": {},
   "source": [
    "### 1:Training the complete encoder+classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae80fb6c-ea25-42c9-a3c2-d71e40136362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "997f9ef3-2acc-4b6f-9b6c-d8973da0ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following script might take very long time to execute on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3308a427-67a7-46bd-97e7-27ca32eb3b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 384, 512, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 256)               93547840  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,683,528\n",
      "Trainable params: 93,683,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "89/89 [==============================] - 631s 7s/step - loss: 50.0177 - sparse_categorical_accuracy: 0.4037 - val_loss: 1.5319 - val_sparse_categorical_accuracy: 0.4346\n",
      "Epoch 2/5\n",
      "89/89 [==============================] - 531s 6s/step - loss: 1.4241 - sparse_categorical_accuracy: 0.5274 - val_loss: 1.5024 - val_sparse_categorical_accuracy: 0.4585\n",
      "Epoch 3/5\n",
      "89/89 [==============================] - 554s 6s/step - loss: 1.1368 - sparse_categorical_accuracy: 0.6171 - val_loss: 1.6946 - val_sparse_categorical_accuracy: 0.4698\n",
      "Epoch 4/5\n",
      "89/89 [==============================] - 561s 6s/step - loss: 0.7985 - sparse_categorical_accuracy: 0.7384 - val_loss: 1.8802 - val_sparse_categorical_accuracy: 0.5105\n",
      "Epoch 5/5\n",
      "89/89 [==============================] - 620s 7s/step - loss: 0.5602 - sparse_categorical_accuracy: 0.8133 - val_loss: 1.7797 - val_sparse_categorical_accuracy: 0.4796\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary()\n",
    "\n",
    "history=classifier.fit(X_train, ytrain,validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbb860-7f6f-4c27-9a2f-ccd722373743",
   "metadata": {},
   "source": [
    "### 2: Freezing the classifier and training the encoder so that encoder learns to predict the most optimal image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "671b2837-2eab-4b62-9f6b-43ac6b37f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = keras.Input(shape=(384,512,3))\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(256, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"encoder_with_projection-head\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e27bd7-f269-4bd4-a51a-a44232602565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\programdata\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-addons) (3.0.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-addons) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typeguard>=2.7->tensorflow-addons) (4.5.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from typeguard>=2.7->tensorflow-addons) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a5326e4-e0d3-49e9-b471-e93073218602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U typing-extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94994f5a-73d8-4638-b313-496e200c2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ffc6-ea74-40da-8c39-dca2df735ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 384, 512, 3)]     0         \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 256)               93547840  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,613,632\n",
      "Trainable params: 93,613,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 682s 6s/step - loss: 3.2870\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 699s 6s/step - loss: 2.8273\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 681s 6s/step - loss: 2.7103\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 782s 7s/step - loss: 2.5435\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 715s 6s/step - loss: 2.4587\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 679s 6s/step - loss: 2.3786\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 658s 6s/step - loss: 2.3081\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 700s 6s/step - loss: 2.2405\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 669s 6s/step - loss: 2.1577\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 826s 7s/step - loss: 2.0412\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 609s 5s/step - loss: 1.9735\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 687s 6s/step - loss: 1.9141\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 636s 6s/step - loss: 1.8344\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 586s 5s/step - loss: 1.8299\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 582s 5s/step - loss: 1.7695\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 1145s 10s/step - loss: 1.7381\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 601s 5s/step - loss: 1.6994\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 1047s 9s/step - loss: 1.7434\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 1520s 14s/step - loss: 1.7158\n",
      "Epoch 20/20\n",
      "  9/112 [=>............................] - ETA: 22:17 - loss: 1.6644"
     ]
    }
   ],
   "source": [
    "learning_rate=0.001\n",
    "temperature=0.05\n",
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(X_train, ytrain,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4f38f-2c97-4b58-892d-7e6c9c77d6d5",
   "metadata": {},
   "source": [
    "### 3: Training the classifier with frozen encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e57638-2b49-4dcb-b6c4-225d35e51374",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=X_train, y=ytrain, validation_split=0.2,batch_size=16, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b583b-1e38-4389-b5cd-a42e166357a4",
   "metadata": {},
   "source": [
    "## Plotting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d42b0-d439-4a0f-9460-5446d005bcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e619f-15eb-4ff4-ab0a-daa8f87beecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5bc5c-224a-40e9-8fe2-0111c085a569",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c2060-6dff-47e7-887e-aecadb13935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f6110-4fa6-46a4-b501-54c4ae4c7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','classifierModel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058741d1-d323-4fd4-985e-59a755ed5175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
